{"docstore/metadata": {"4dd8aedb-33cd-4ab2-a277-37848a858943": {"doc_hash": "f52b019b6c5f08dc80203b6c84f2e6547375027122b59bb708288676f449c454"}, "1d84a17d-eed7-4410-a557-5e5ecf45c124": {"doc_hash": "a6e21aad92bc74450e0c08ae173d290dc1158a82b657fbb87b42ac4b291e125c"}, "85e46633-f5fb-4355-9b6a-d2c8318f2df4": {"doc_hash": "6c896d25ebf949900898a9081e2a4a31f8a6c7046a506753f657ba4f8cd80f1c"}, "9528c592-9814-45f2-8854-4912d38c4e11": {"doc_hash": "c41a339052b4e373e4676d6e877e5165c0a7175a9d29ee25ca414917aae57ab9"}, "2b293a6c-de02-4cc7-8871-5aa8802cc2d0": {"doc_hash": "be34d72ca3371e7c03f82e35faad9431a07548453f1b37b64fc65820ae9e5c4e"}, "76466c9d-f2e7-4924-b5f2-fa774f842fd2": {"doc_hash": "5189c00279983cbbb6612da728a8e6432adceb5394894410d673a1007f1bd7d3", "ref_doc_id": "4dd8aedb-33cd-4ab2-a277-37848a858943"}, "f72f069d-fb6d-4049-a8dc-e689501ca014": {"doc_hash": "44d1529f957088544cc17c4ee8f2f8664ccc711f051d91f6f7e5399328d443e2", "ref_doc_id": "1d84a17d-eed7-4410-a557-5e5ecf45c124"}, "41937f67-fadf-4e15-bf9b-d79c3afe4f9b": {"doc_hash": "9a58e786c0871992788afd78efad6e6c70a669ae3a7503d3bd9f5ab9b34949c8", "ref_doc_id": "85e46633-f5fb-4355-9b6a-d2c8318f2df4"}, "f5dc85a3-9eb5-4082-8e67-6c94ea73e8e7": {"doc_hash": "ced86dd48c15031cbb33d7cca5d1e80f77d2b3d7250d4772cb6930bfa18577ec", "ref_doc_id": "9528c592-9814-45f2-8854-4912d38c4e11"}, "f92d757b-6f63-478b-9d2d-ff02b56fb2b2": {"doc_hash": "3ca1c78893938fc42b1d1b8c8be8780e1cb3f043505c221b203e4cfa9b48f9ca", "ref_doc_id": "2b293a6c-de02-4cc7-8871-5aa8802cc2d0"}}, "docstore/ref_doc_info": {"4dd8aedb-33cd-4ab2-a277-37848a858943": {"node_ids": ["76466c9d-f2e7-4924-b5f2-fa774f842fd2"], "metadata": {"topic": "vector_databases", "difficulty": "intermediate", "year": 2023}}, "1d84a17d-eed7-4410-a557-5e5ecf45c124": {"node_ids": ["f72f069d-fb6d-4049-a8dc-e689501ca014"], "metadata": {"topic": "algorithms", "difficulty": "advanced", "year": 2023}}, "85e46633-f5fb-4355-9b6a-d2c8318f2df4": {"node_ids": ["41937f67-fadf-4e15-bf9b-d79c3afe4f9b"], "metadata": {"topic": "embeddings", "difficulty": "beginner", "year": 2024}}, "9528c592-9814-45f2-8854-4912d38c4e11": {"node_ids": ["f5dc85a3-9eb5-4082-8e67-6c94ea73e8e7"], "metadata": {"topic": "qdrant", "difficulty": "intermediate", "year": 2024}}, "2b293a6c-de02-4cc7-8871-5aa8802cc2d0": {"node_ids": ["f92d757b-6f63-478b-9d2d-ff02b56fb2b2"], "metadata": {"topic": "chroma", "difficulty": "beginner", "year": 2024}}}, "docstore/data": {"76466c9d-f2e7-4924-b5f2-fa774f842fd2": {"__data__": {"id_": "76466c9d-f2e7-4924-b5f2-fa774f842fd2", "embedding": null, "metadata": {"topic": "vector_databases", "difficulty": "intermediate", "year": 2023}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4dd8aedb-33cd-4ab2-a277-37848a858943", "node_type": "4", "metadata": {"topic": "vector_databases", "difficulty": "intermediate", "year": 2023}, "hash": "f52b019b6c5f08dc80203b6c84f2e6547375027122b59bb708288676f449c454", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Vector databases are specialized databases designed to store and query high-dimensional vectors.\n        These vectors typically represent embeddings of text, images, or other data. Vector databases\n        enable efficient similarity search using algorithms like HNSW (Hierarchical Navigable Small World)\n        or IVF (Inverted File Index). Popular vector databases include Qdrant, Pinecone, Weaviate, and Milvus.", "mimetype": "text/plain", "start_char_idx": 9, "end_char_idx": 425, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f72f069d-fb6d-4049-a8dc-e689501ca014": {"__data__": {"id_": "f72f069d-fb6d-4049-a8dc-e689501ca014", "embedding": null, "metadata": {"topic": "algorithms", "difficulty": "advanced", "year": 2023}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d84a17d-eed7-4410-a557-5e5ecf45c124", "node_type": "4", "metadata": {"topic": "algorithms", "difficulty": "advanced", "year": 2023}, "hash": "a6e21aad92bc74450e0c08ae173d290dc1158a82b657fbb87b42ac4b291e125c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "HNSW (Hierarchical Navigable Small World) is a graph-based algorithm for approximate nearest neighbor\n        search. It builds a multi-layer graph where each layer is a subset of the previous one. The algorithm\n        achieves excellent query performance (sub-millisecond) with high recall. HNSW parameters include\n        M (number of connections per node) and ef_construction (search width during construction).", "mimetype": "text/plain", "start_char_idx": 9, "end_char_idx": 424, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "41937f67-fadf-4e15-bf9b-d79c3afe4f9b": {"__data__": {"id_": "41937f67-fadf-4e15-bf9b-d79c3afe4f9b", "embedding": null, "metadata": {"topic": "embeddings", "difficulty": "beginner", "year": 2024}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "85e46633-f5fb-4355-9b6a-d2c8318f2df4", "node_type": "4", "metadata": {"topic": "embeddings", "difficulty": "beginner", "year": 2024}, "hash": "6c896d25ebf949900898a9081e2a4a31f8a6c7046a506753f657ba4f8cd80f1c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Embedding models convert text into dense vector representations that capture semantic meaning.\n        OpenAI's text-embedding-3-small produces 1536-dimensional vectors and is optimized for retrieval tasks.\n        Open-source alternatives include sentence-transformers models like all-MiniLM-L6-v2 (384 dimensions)\n        and all-mpnet-base-v2 (768 dimensions). The choice of embedding model affects retrieval quality and cost.", "mimetype": "text/plain", "start_char_idx": 9, "end_char_idx": 438, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f5dc85a3-9eb5-4082-8e67-6c94ea73e8e7": {"__data__": {"id_": "f5dc85a3-9eb5-4082-8e67-6c94ea73e8e7", "embedding": null, "metadata": {"topic": "qdrant", "difficulty": "intermediate", "year": 2024}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9528c592-9814-45f2-8854-4912d38c4e11", "node_type": "4", "metadata": {"topic": "qdrant", "difficulty": "intermediate", "year": 2024}, "hash": "c41a339052b4e373e4676d6e877e5165c0a7175a9d29ee25ca414917aae57ab9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Qdrant is an open-source vector database written in Rust. It supports HNSW indexing, filtering,\n        and hybrid search. Qdrant can run locally (Docker) or in the cloud. Key features include payload\n        filtering, quantization for memory reduction, and distributed deployments. Qdrant is particularly\n        well-suited for production RAG applications.", "mimetype": "text/plain", "start_char_idx": 9, "end_char_idx": 368, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f92d757b-6f63-478b-9d2d-ff02b56fb2b2": {"__data__": {"id_": "f92d757b-6f63-478b-9d2d-ff02b56fb2b2", "embedding": null, "metadata": {"topic": "chroma", "difficulty": "beginner", "year": 2024}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2b293a6c-de02-4cc7-8871-5aa8802cc2d0", "node_type": "4", "metadata": {"topic": "chroma", "difficulty": "beginner", "year": 2024}, "hash": "be34d72ca3371e7c03f82e35faad9431a07548453f1b37b64fc65820ae9e5c4e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Chroma is a lightweight, embedded vector database designed for AI applications. It runs in-memory\n        or can persist to disk. Chroma is easy to set up and integrates seamlessly with LangChain and LlamaIndex.\n        It's ideal for prototyping and small-to-medium scale applications. Chroma supports metadata filtering\n        and multiple distance metrics (cosine, euclidean, dot product).", "mimetype": "text/plain", "start_char_idx": 9, "end_char_idx": 402, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}